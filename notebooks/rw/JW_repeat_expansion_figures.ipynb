{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AoU_WDL'...\n",
      "remote: Enumerating objects: 324, done.\u001b[K\n",
      "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
      "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
      "remote: Total 324 (delta 29), reused 48 (delta 14), pack-reused 255\u001b[K\n",
      "Receiving objects: 100% (324/324), 61.45 KiB | 2.93 MiB/s, done.\n",
      "Resolving deltas: 100% (165/165), done.\n",
      "Building synchronization state...\n",
      "Starting synchronization...\n",
      "Copying file://AoU_WDL/bam_to_contig/bam_to_contig.json [Content-Type=application/json]...\n",
      "Copying file://AoU_WDL/bam_to_contig/bam_to_contig.sh [Content-Type=text/x-sh]...\n",
      "Copying file://AoU_WDL/bam_to_contig/bam_to_contig.wdl [Content-Type=application/octet-stream]...\n",
      "Copying file://AoU_WDL/bam_to_contig/concat_contigs.py [Content-Type=text/x-python]...\n",
      "/ [4 files][  8.1 KiB/  8.1 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m rsync ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://AoU_WDL/bam_to_contig/make_contig_bed.py [Content-Type=text/x-python]...\n",
      "Copying file://AoU_WDL/bam_to_contig/run_samtools_faidx_for_sample.sh [Content-Type=text/x-sh]...\n",
      "/ [6 files][  9.9 KiB/  9.9 KiB]                                                \n",
      "Operation completed over 6 objects/9.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BUCKET = os.getenv('WORKSPACE_BUCKET')\n",
    "!git clone https://github.com/EichlerLab/AoU_WDL.git\n",
    "!gsutil rsync -r AoU_WDL/bam_to_contig {BUCKET}/cromwell_input/bam_to_contig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -u $GOOGLE_PROJECT ls gs://fc-aou-datasets-controlled/pooled/longreads/v7_base/hifiasm/ | xargs -n 1 basename > samples.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract haplotigs at locus of interest\n",
    "import os\n",
    "\n",
    "BUCKET = os.getenv('WORKSPACE_BUCKET')\n",
    "with open('fmr1_t2t.bed', 'w') as out_f:\n",
    "    out_f.write('chrX\\t146176546\\t146176888\\n')\n",
    "#FMR1        chrX:146176546-146176888 (UTR through Exon 2)\n",
    "#HTT         chr4:3073552-3073843 (Exon 1-2)\n",
    "GENE_COORDS_BED = 'fmr1_t2t.bed'\n",
    "with open(GENE_COORDS_BED) as f:\n",
    "    coords = f.readline().strip().split()\n",
    "    FLANK_BP = int(coords[2]) - int(coords[1])\n",
    "\n",
    "with open('samples.txt') as f:\n",
    "     samples = f.readlines()\n",
    "        \n",
    "with open('ordered_sample_names_w_hap.txt', 'w') as out_sample, open('ordered_haplotig_fasta_names.txt', 'w') as out_fasta, open('ordered_bam_names.txt', 'w') as out_bam, open('ordered_bai_names.txt', 'w') as out_bai:\n",
    "    for sample in samples:\n",
    "        for hap in ['1', '2']:\n",
    "            out_sample.write(f'{sample}_hap{hap}\\n')\n",
    "            out_fasta.write(f'gs://fc-aou-preprod-datasets-controlled/pooled/longreads/v7_base/assembly/hifiasm/{sample}/{sample}.haploTigs/{sample}.bp.hap{hap}.p_ctg.fa.gz\\n')\n",
    "            out_bam.write(f'{BUCKET}/alpha2-t2t/asm_align/bam/{sample}-asm_h{hap}.minimap2.bam\\n')\n",
    "            out_bai.write(f'{BUCKET}/alpha2-t2t/asm_align/bam/{sample}-asm_h{hap}.minimap2.bam.bai\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://fmr1_t2t.bed [Content-Type=application/octet-stream]...\n",
      "/ [1 files][   25.0 B/   25.0 B]                                                \n",
      "Operation completed over 1 objects/25.0 B.                                       \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {GENE_COORDS_BED} {BUCKET}/cromwell_input/bam_to_contig/{GENE_COORDS_BED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "d = {\n",
    "  \"bam_to_contig.bam_to_contig_bash_script\": f\"{BUCKET}/cromwell_input/bam_to_contig/bam_to_contig.sh\",\n",
    "  \"bam_to_contig.make_contig_bed_script\": f\"{BUCKET}/cromwell_input/bam_to_contig/make_contig_bed.py\",\n",
    "  \"bam_to_contig.ordered_sample_names_w_hap\": f\"{BUCKET}/cromwell_input/bam_to_contig/ordered_sample_names_w_hap.txt\",\n",
    "  \"bam_to_contig.ordered_bams\": f\"{BUCKET}/cromwell_input/bam_to_contig/ordered_bam_names.txt\",\n",
    "  \"bam_to_contig.ordered_bais\": f\"{BUCKET}/cromwell_input/bam_to_contig/ordered_bai_names.txt\",\n",
    "  \"bam_to_contig.ordered_haplotig_fastas\": f\"{BUCKET}/cromwell_input/bam_to_contig/ordered_haplotig_fasta_names.txt\",\n",
    "  \"bam_to_contig.regions_bed\": f\"{BUCKET}/cromwell_input/bam_to_contig/{GENE_COORDS_BED}\",\n",
    "  \"bam_to_contig.flank_bp\": f\"{FLANK_BP}\",\n",
    "  \"bam_to_contig.run_faidx_script\": f\"{BUCKET}/cromwell_input/bam_to_contig/run_samtools_faidx_for_sample.sh\",\n",
    "  \"bam_to_contig.concat_contigs_script\": f\"{BUCKET}/cromwell_input/bam_to_contig/concat_contigs.py\"\n",
    "}\n",
    "with open('bam_to_contig.json', 'w') as out_f:\n",
    "    out_f.write(json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for cromshell 2\n",
      "Found cromshell, please use cromshell\n",
      "Checking status for CROMWELL app\n",
      "Updating cromwell config\n",
      "CROMWELL app does not exist. Please create cromwell server from workbench\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def check_for_app(env):\n",
    "    list_apps_url = f'{env[\"leonardo_url\"]}/api/google/v1/apps/{env[\"google_project\"]}'\n",
    "    r = requests.get(\n",
    "        list_apps_url,\n",
    "        params={\n",
    "          'includeDeleted': 'false'\n",
    "        },\n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {env[\"token\"]}'\n",
    "        }\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "\n",
    "    for potential_app in r.json():\n",
    "        if potential_app['appType'] == 'CROMWELL' and (\n",
    "                str(potential_app['auditInfo']['creator']) == env['owner_email']\n",
    "                or str(potential_app['auditInfo']['creator']) == env['user_email']\n",
    "        ) :\n",
    "            potential_app_name = potential_app['appName']\n",
    "            potential_app_status = potential_app['status']\n",
    "\n",
    "            # We found a CROMWELL app in the correct google project and owned by the user. Now just check the workspace:\n",
    "            _, workspace_namespace,  proxy_url = get_app_details(env, potential_app_name)\n",
    "            if workspace_namespace == env['workspace_namespace']:\n",
    "                return potential_app_name, potential_app_status, proxy_url['cromwell-service']\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "def get_app_details(env, app_name):\n",
    "    get_app_url = f'{env[\"leonardo_url\"]}/api/google/v1/apps/{env[\"google_project\"]}/{app_name}'\n",
    "    print('start')\n",
    "    r = requests.get(\n",
    "        get_app_url,\n",
    "        params={\n",
    "            'includeDeleted': 'true',\n",
    "            'role': 'creator'\n",
    "        },\n",
    "        headers={\n",
    "            'Authorization': f'Bearer {env[\"token\"]}'\n",
    "        }\n",
    "    )\n",
    "    if r.status_code == 404:\n",
    "        return 'DELETED', None, None, None\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "    result_json = r.json()\n",
    "    custom_environment_variables = result_json['customEnvironmentVariables']\n",
    "    return result_json['status'], custom_environment_variables['WORKSPACE_NAMESPACE'], result_json.get('proxyUrls')\n",
    "\n",
    "# Checks that cromshell is installed. Otherwise raises an error.\n",
    "def validate_cromshell():\n",
    "    if validate_cromshell_alias():\n",
    "        print(\"Found cromshell, please use cromshell\")\n",
    "    elif validate_cromshell_alpha():\n",
    "        print(\"Found cromshell-alpha, please use cromshell-alpha\")\n",
    "    else:\n",
    "        raise Exception(\"Cromshell is not installed.\")\n",
    "\n",
    "# Checks that cromshell is installed. Otherwise raises an error.\n",
    "def validate_cromshell_alpha():\n",
    "    print('Scanning for cromshell 2 alpha...')\n",
    "    try:\n",
    "        subprocess.run(['cromshell-alpha', 'version'], capture_output=True, check=True, encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        return False\n",
    "    return True\n",
    "# Checks that cromshell is installed. Otherwise raises an error.\n",
    "def validate_cromshell_alias():\n",
    "    print('Scanning for cromshell 2')\n",
    "    try:\n",
    "        subprocess.run(['cromshell', 'version'], capture_output=True, check=True, encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def configure_cromwell(env, proxy_url):\n",
    "     print('Updating cromwell config')\n",
    "     file = f'{str(Path.home())}/.cromshell/cromshell_config.json'\n",
    "     configuration = {\n",
    "        'cromwell_server': proxy_url.split(\"swagger/\", 1)[0] if proxy_url else \"invalid url\",\n",
    "        'requests_timeout': 5,\n",
    "        'gcloud_token_email': env['user_email'],\n",
    "        'referer_header_url': env['leonardo_url']\n",
    "     }\n",
    "     with open(file, 'w') as filetowrite:\n",
    "        filetowrite.write(json.dumps(configuration, indent=2))\n",
    "\n",
    "def find_app_status(env):\n",
    "    print(f'Checking status for CROMWELL app')\n",
    "    app_name, app_status, proxy_url = check_for_app(env)\n",
    "\n",
    "    configure_cromwell(env, proxy_url)\n",
    "\n",
    "    if app_name is None:\n",
    "        print(f'CROMWELL app does not exist. Please create cromwell server from workbench')\n",
    "    else:\n",
    "        print(f'app_name={app_name}; app_status={app_status}')\n",
    "        print(f'Existing CROMWELL app found (app_name={app_name}; app_status={app_status}).')\n",
    "        exit(1)\n",
    "\n",
    "def main():\n",
    "    # Iteration 1: these ENV reads will throw errors if not set.\n",
    "    env = {\n",
    "        'workspace_namespace': os.environ['WORKSPACE_NAMESPACE'],\n",
    "        'workspace_bucket': os.environ['WORKSPACE_BUCKET'],\n",
    "        'user_email': os.environ.get('PET_SA_EMAIL', default = os.environ['OWNER_EMAIL']),\n",
    "        'owner_email': os.environ['OWNER_EMAIL'],\n",
    "        'google_project': os.environ['GOOGLE_PROJECT'],\n",
    "        'leonardo_url': os.environ['LEONARDO_BASE_URL']\n",
    "    }\n",
    "\n",
    "    # Before going any further, check that cromshell2 is installed:\n",
    "    validate_cromshell()\n",
    "\n",
    "    # Fetch the token:\n",
    "    token_fetch_command = subprocess.run(['gcloud', 'auth', 'print-access-token', env['user_email']], capture_output=True, check=True, encoding='utf-8')\n",
    "    env['token'] = str.strip(token_fetch_command.stdout)\n",
    "\n",
    "    find_app_status(env)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cromshell submit AoU_WDL/bam_to_contig/bam_to_contig.wdl bam_to_contig.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/EichlerLab/compteam_tools.git\n",
    "!python compteam_tools/visualize_repeat_region/make_viz.py compteam_tools/visualize_repeat_region/fmr1_params_example.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
